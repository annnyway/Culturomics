{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# most simple spell correction baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вытащим только неправильные варианты и заодно посчитаем процент ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(index):\n",
    "    df = pd.read_csv(index + \".csv\")\n",
    "    df.columns = ['raw_ngram', 'year', 'match_count', 'volume_count', 'idx', 'n_gram',\n",
    "       'new_idx', 'is_bastard', 'new_ngram']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = getNgrams('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = a[a.new_ngram == '']\n",
    "total = len(a)\n",
    "print('Доля ошибок - ', len(mistakes)/total )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обернем в Counter, чтобы сразу увидеть частотные ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(mistakes).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за того, что процент ошибок довольно низкий, не очень выгодно будет находить исправление для каждого слова. Нужен какой-то более простой классификатор, который выделит ошибочные слова, чтобы потом только их и редактировать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ выделить ошибочные слова - составить словарь правильных слов и потом сравнивать с ним. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы заранее собрали небольшой корпус текстов с дореволюционной орфографией и немного почистили его удалив отдельную пунктуацию и пунктуацию на границах слов, цифры и латиницу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = open('vocabulary.txt', 'r').read()\n",
    "vocab = []\n",
    "for line in vocabulary.split(\"\\n\"):\n",
    "    vocab.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['абажуру',\n",
       " 'абажуръ',\n",
       " 'абаза',\n",
       " 'абазай',\n",
       " 'абазая',\n",
       " 'абазеховъ',\n",
       " 'абазинка',\n",
       " 'абазинск',\n",
       " 'абазинскимъ',\n",
       " 'абазинцевъ',\n",
       " 'абазъ',\n",
       " 'абазы',\n",
       " 'абаи',\n",
       " 'абаками',\n",
       " 'абакана',\n",
       " 'абаканомъ',\n",
       " 'абаканскимъ',\n",
       " 'абаканской',\n",
       " 'абаканску',\n",
       " 'абаканскъ']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# нормализация нам тут не нужна так как нужно находить слова в разных формах\n",
    "vocab[70:90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Проверка на нахождение в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mistaken(word, vocab):\n",
    "    '''\n",
    "    ::input: word, vocabulary\n",
    "    ::output: 1 or 0\n",
    "    '''\n",
    "    return(0 if word in vocab else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация исправлений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading a corpus\n",
      "Estimating cospus size\n"
     ]
    }
   ],
   "source": [
    "%run VocabMaker.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно думать о том, как исправить неправильные слова. Посмотрим как это можно делать на примере известной реализации Питера Норвига."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея - сделать словарь правильных слов (у нас уже есть), расчитать вероятность каждого слова в корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = VM.corpus\n",
    "WORDS = Counter(VM.corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('а', 1),\n",
       " ('аа', 1),\n",
       " ('ааа', 1),\n",
       " ('аааа', 1),\n",
       " ('аабб', 1),\n",
       " ('аавв', 1),\n",
       " ('аагаарду', 1),\n",
       " ('аадамауа', 1),\n",
       " ('аалбуха', 1),\n",
       " ('аалбухъ', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# фунцкия расчета вероятности слова\n",
    "N = sum(WORDS.values())\n",
    "def P(word, N=N): \n",
    "    \"Вычисляем вероятность слова\"\n",
    "    p = WORDS[word] / N\n",
    "    return p #if not p==0 else 1/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8856031487701557e-06"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P('есмы')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы найти исправления нужно сгенерировать возможные исправления и выбрать те, которые есть в словаре. Если есть несколько вариантов, то выбрать тот, у котогоро наибольшая вероятность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): \n",
    "    \"Находим наиболее вероятное похожее слово\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Генерируем кандидатов на исправление\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"Выбираем слова, которые есть в корпусе\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"Создаем кандидатов, которые отличаются на одну букву\"\n",
    "    letters    = 'йцукенгшщзхъфывапролджэячсмиітьѣѳбю'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"Создаем кандидатов, которые отличаются на две буквы\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 31.2 ms, total: 31.2 ms\n",
      "Wall time: 18.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'пушкин'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correction('пузкин')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "что происходит в функции edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'пузкин'\n",
    "splits = [(word[:i], word[i:])    for i in range(len(word) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'пузкин'),\n",
       " ('п', 'узкин'),\n",
       " ('пу', 'зкин'),\n",
       " ('пуз', 'кин'),\n",
       " ('пузк', 'ин'),\n",
       " ('пузки', 'н'),\n",
       " ('пузкин', '')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "deletes = [L + R[1:] for L, R in splits if R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['узкин', 'пзкин', 'пукин', 'пузин', 'пузкн', 'пузки']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deletes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['упзкин', 'пзукин', 'пукзин', 'пузикн', 'пузкни']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters    = 'йцукенгшщзхъфывапролджэячсмиітьѣѳбюѵ'\n",
    "replaces = [L + c + R[1:] for L, R in splits if R for c in letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "inserts = [L + c + R for L, R in splits for c in letters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['йпузкин',\n",
       " 'цпузкин',\n",
       " 'упузкин',\n",
       " 'кпузкин',\n",
       " 'епузкин',\n",
       " 'нпузкин',\n",
       " 'гпузкин',\n",
       " 'шпузкин',\n",
       " 'щпузкин',\n",
       " 'зпузкин']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inserts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки используем просто долю правильных исправлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.860593220338983\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим какие исправления выбираются для самых частотных опечаток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(wt[0], wt[1], correction(wt[1])) for wt, _ in Counter(mistakes).most_common(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики близости слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо того, чтобы генерировать все варианты, можно искать похожие слова в словаре. Для этого нужно задать метрику похожести. Для исправления опечаток часто используются расстояния редактирования (количество редактирований, которые нужно сделать в строке a, чтобы прийти к b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в питоне есть библиотеке для нахождения близких строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 548 ms, sys: 0 ns, total: 548 ms\n",
      "Wall time: 546 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['апофеоз']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_close_matches('опофеоз', WORDS.keys(), n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работает тоже не очень быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Недавно вышла библиотека, в которой реализованы многие методы нахождения расстояний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(text, lookup, metric=textdistance.levenshtein):\n",
    "    similarities = Counter()\n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "    \n",
    "    return similarities.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 868 ms, sys: 4 ms, total: 872 ms\n",
      "Wall time: 891 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('апофеоз', 0.7142857142857143)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_match_with_metric('опофиоз', WORDS, textdistance.hamming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.2 s, sys: 0 ns, total: 12.2 s\n",
      "Wall time: 12.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('апофеоз', 0.8571428571428572)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_match_with_metric('апофиоз', WORDS, textdistance.levenshtein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "есть что-то побыстрее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Многие вещи, которые медленно решаются в питоне, можно оптимизировать с помощью матричных и векторных операций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "можно сделать поиск похожих по векторам символов, из которых состоит слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [sent.split() for sent in open('corpus_ng.txt', encoding='utf8').read().splitlines()]\n",
    "WORDS = Counter()\n",
    "for sent in corpus:\n",
    "    WORDS.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(WORDS.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_vec(text, X, vec, TOPN=3):\n",
    "    v = vec.transform([text])\n",
    "    similarities = cosine_distances(v, X)\n",
    "    topn = similarities.argsort()[0][:TOPN]\n",
    "    \n",
    "    return [id2word[top] for top in topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_closest_match_vec('пузкин', X, vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рассмотренных методах при выборе исправления никак не использовался контекст. Про то как это можно сделать, можно почитать в `literature\\spellchecking.pdf`, http://www.dialog-21.ru/media/3429/sorokinaashavrinato.pdf"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
